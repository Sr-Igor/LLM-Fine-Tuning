# ğŸ§  Planus Finetuner - Guia de UtilizaÃ§Ã£o

Este projeto automatiza a criaÃ§Ã£o de um Assistente de IA Especializado (Planus) para o ERP Planuze. Ele utiliza documentos PDF/TXT para gerar conhecimento e treina modelos (Llama 3.1 ou Qwen 2.5) para responder perguntas tÃ©cnicas seguindo regras de negÃ³cio estritas.

---

## ğŸ› ï¸ 1. PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de que vocÃª possui:

- **Para Gerar Dados:** Qualquer computador (Mac, Windows, Linux) com **Python 3.10+** e **Ollama** instalado.
- **Para Treinar (Fine-Tuning):** Um servidor ou PC com **GPU NVIDIA** (mÃ­nimo 8GB VRAM, ideal 24GB RTX 3090/4090) rodando Linux ou WSL2.
- **Contas:**
  - **Hugging Face:** Token com permissÃ£o de leitura/escrita (para baixar/subir modelos).
  - **WandB (Opcional):** Para acompanhar grÃ¡ficos de treino em tempo real.

---

## ğŸš€ 2. ConfiguraÃ§Ã£o Inicial

### 2.1. Clone e Ambiente Virtual

```bash
git clone <URL_DO_REPOSITORIO>
cd planuze-llm

# Crie o ambiente virtual (Python 3.10 recomendado)
python3.10 -m venv venv
source venv/bin/activate
```

### 2.2. InstalaÃ§Ã£o de DependÃªncias

O projeto possui um **Makefile** para facilitar os comandos.

- **Se estiver no Mac (apenas geraÃ§Ã£o de dados):**
  Abra o `requirements.txt` e comente as linhas abaixo de "DEPENDÃŠNCIAS EXCLUSIVAS NVIDIA". Execute:

  ```bash
  make install
  ```

- **Se estiver no Linux/GPU (para treino):**
  Execute direto:
  ```bash
  make install
  ```

### 2.3. VariÃ¡veis de Ambiente

Configure as variÃ¡veis copiando o exemplo:

```bash
cp .env.example .env
```

Edite o arquivo `.env`:

- `HF_TOKEN`: Seu token do Hugging Face.
- `OLLAMA_HOST`: URL do Ollama (padrÃ£o `http://localhost:11434`).
- ConfiguraÃ§Ãµes de diretÃ³rios (se quiser alterar os padrÃµes).

---

## ğŸ“š 3. Fase de Dados (Rodar no Mac/Local)

Transforme PDFs brutos em um dataset JSONL limpo para o treino.

### Passo A: IngestÃ£o de Documentos

Coloque seus manuais, polÃ­ticas e documentos tÃ©cnicos (PDF ou TXT) na pasta:
ğŸ“‚ **`data/source_documents/`**

### Passo B: GeraÃ§Ã£o e Processamento

Para gerar os dados sintÃ©ticos via Ollama, fundir com dados manuais (se houver) e validar o dataset, apenas execute:

```bash
make data
```

> **O que esse comando faz?**
>
> 1. Executa `src/synthetic_data_gen.py`: LÃª PDFs e usa o Ollama para criar pares Pergunta/Resposta.
> 2. Executa `src/dataset_merger.py`: Junta os dados sintÃ©ticos com `data/raw/manual_rules.jsonl` (opcional), valida o JSON e embaralha.

**SaÃ­da Final:** ğŸ“‚ `data/processed/train_dataset_final.jsonl`

---

## ğŸ‹ï¸ 4. Fase de Treinamento (Rodar no Servidor GPU)

Mova o projeto (ou a pasta `data/processed`) para a mÃ¡quina com GPU.

### Passo A: ConfiguraÃ§Ã£o do Treino

Abra o arquivo `main.py` e ajuste a configuraÃ§Ã£o em `project_config`:

- **Model Name:** `unsloth/Qwen2.5-32B-Instruct` ou `unsloth/Meta-Llama-3.1-8B-Instruct`.
- **Max Steps:** `60` para testes rÃ¡pidos, `300+` para produÃ§Ã£o.
- **Final Model Name:** Caminho de saÃ­da (ex: `models/planus_qwen_v1`).

### Passo B: Executar o Fine-Tuning

```bash
make train
```

> **O processo:**
>
> 1. Baixa o modelo base e aplica adaptadores LoRA.
> 2. Inicia o treinamento supervisionado (SFT).
> 3. Converte e salva o modelo final em formato GGUF na pasta `models/`.

---

## ğŸ’¬ 5. Fase de Uso (Deploy no Ollama)

Com o modelo GGUF salvo, vocÃª pode testÃ¡-lo imediatamente no Ollama.

Se o modelo foi salvo e vocÃª tem um `Modelfile` configurado na raiz (apontando para o GGUF gerado), execute:

```bash
make run
```

Isso irÃ¡ criar o modelo `planus-pro` no seu Ollama local e abrir o chat interativo.

---

## ğŸ”„ Resumo do Ciclo de Vida (Cheat Sheet)

| AÃ§Ã£o                             | Comando        |
| :------------------------------- | :------------- |
| **Instalar DependÃªncias**        | `make install` |
| **Gerar Dataset (PDF -> JSONL)** | `make data`    |
| **Treinar Modelo (GPU)**         | `make train`   |
| **Rodar Chat (Ollama)**          | `make run`     |
| **Limpar TemporÃ¡rios**           | `make clean`   |

---

## ğŸ“‚ Estrutura de Pastas

```text
planuze-llm/
â”œâ”€â”€ config/             # Classes de configuraÃ§Ã£o
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ source_documents/  # [ENTRADA] Seus PDFs aqui
â”‚   â”œâ”€â”€ raw/               # Dados intermediÃ¡rios (sintÃ©ticos/manuais)
â”‚   â””â”€â”€ processed/         # [SAÃDA] Dataset final pronto para treino
â”œâ”€â”€ models/             # Onde o GGUF final serÃ¡ salvo
â”œâ”€â”€ src/                # Scripts de lÃ³gica (geraÃ§Ã£o, treino, merge)
â”œâ”€â”€ .env                # Tokens e configuraÃ§Ãµes
â”œâ”€â”€ Makefile            # Atalhos de comando
â””â”€â”€ main.py             # Script de treino
```
