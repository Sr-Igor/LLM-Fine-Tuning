## ESSE √â UM ARQUIVO DE SUGEST√ÉO DE CONFIGURA√á√ÉO DAS ENVS PARA O COLAB FREE

# ==========================================
# üîê AUTENTICA√á√ÉO E ACESSOS
# ==========================================
# Crie um token "Write" em: https://huggingface.co/settings/tokens
HF_TOKEN=hf_seu_token_aqui

# ==========================================
# üìä MONITORAMENTO
# ==========================================
WANDB_API_KEY=wandb_sua_key_aqui
WANDB_PROJECT=planus-llm-collab
# Manter false para economizar recursos de upload em background
WANDB_WATCH=false

# ==========================================
# ü§ñ CONFIGURA√á√ïES GERAIS
# ==========================================
OLLAMA_HOST=http://localhost:11434

# Modelo para gera√ß√£o sint√©tica (se necess√°rio).
# Qwen 7B √© mais leve que Llama 3 para rodar no background do Colab.
GENERATOR_MODEL=qwen2.5:7b

# ==========================================
# üèãÔ∏è CONFIGURA√á√ïES DE TREINAMENTO (Estabilidade T4)
# ==========================================

# Modelo Base: 7B √© o limite seguro para a Tesla T4 (16GB VRAM).
# O 32B causar√° OOM (Out of Memory) instant√¢neo.
MODEL_NAME="unsloth/Qwen2.5-7B-Instruct"

# Context Window (CR√çTICO)
# Reduzido de 2048 para 1024 para garantir estabilidade na T4.
# Isso evita estouro de VRAM durante picos de gradiente.
MAX_SEQ_LENGTH=1024

# Obrigat√≥rio para GPUs de consumo/Colab.
LOAD_IN_4BIT=true

# --- Par√¢metros de Treino ---

# Passos de treino. 60-100 √© um bom range para fine-tuning inicial.
TRAINING_MAX_STEPS=100

# Batch Size conservador.
TRAINING_BATCH_SIZE=2

# Ac√∫mulo de gradientes para simular um batch maior (2 * 4 = 8).
TRAINING_GRAD_ACCUMULATION=4

# Warmup para estabilizar o in√≠cio do aprendizado.
TRAINING_WARMUP_STEPS=10

# Taxa de aprendizado padr√£o para QLoRA.
TRAINING_LEARNING_RATE=2e-4

TRAINING_SEED=3407

# Limitado a 2 n√∫cleos para n√£o travar o dataloader do Colab.
TRAINING_DATASET_NUM_PROC=2

# --- Diret√≥rios (Focados no Drive) ---
TRAINING_OUTPUT_DIR="outputs_checkpoints"
DATASET_PATH="data/processed/train_dataset_final.jsonl"
FINAL_MODEL_NAME="planus_qwen_v1"

# ==========================================
# üß© DADOS SINT√âTICOS
# ==========================================
SYNTHETIC_CHUNK_SIZE=1500
SYNTHETIC_OVERLAP=150
SYNTHETIC_SOURCE_DIR="data/source_documents"
SYNTHETIC_OUTPUT_FILE="data/raw/train_data_synthetic.jsonl"
SYNTHETIC_GENERATOR_MODEL="qwen2.5:7b"
# Prompt minificado para evitar erros de leitura do arquivo .env
SYNTHETIC_SYSTEM_INSTRUCTION="Voc√™ √© o Assistente. Responda tecnicamente sobre o ERP Planuze. Regras: 1. Use PT-BR. 2. Datas dd/mm/aaaa. 3. Nunca cite IDs internos ou SQL. 4. Seja direto."

# ==========================================
# ‚öôÔ∏è OTIMIZA√á√ÉO DE HARDWARE
# ==========================================

# Otimizador de 8-bit economiza ~70% de mem√≥ria nos estados do otimizador.
TRAINING_OPTIM="adamw_8bit"

TRAINING_WEIGHT_DECAY=0.01
TRAINING_LR_SCHEDULER="linear"

# ==========================================
# üîß LORA & EXPORTA√á√ÉO
# ==========================================

LORA_R=16
LORA_ALPHA=16
LORA_DROPOUT=0
LORA_TARGET_MODULES='["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]'
LORA_RANDOM_STATE=3407

# Formato de exporta√ß√£o para o Mac (Ollama)
GGUF_QUANTIZATION="q4_k_m"