# ==========================================
# üèãÔ∏è CONFIGURA√á√ïES DE TREINAMENTO (CUDA/Unsloth)
# ==========================================
# Renomeie para envs/.env.cuda
# ==========================================

# Modelo Base para o Fine-Tuning
# Ex: unsloth/Qwen2.5-32B-Instruct, unsloth/Llama-3.1-8B-Instruct
MODEL_NAME="unsloth/Qwen2.5-32B-Instruct"

# Tamanho m√°ximo da sequ√™ncia (Context Window)
MAX_SEQ_LENGTH=2048

# Carregar em 4-bit para economizar mem√≥ria? (True/False)
LOAD_IN_4BIT=true

# --- Par√¢metros de Treino ---

# Quantos passos de treino executar.
TRAINING_MAX_STEPS=60

# Tamanho do Batch (Exemplos processados simultaneamente por GPU).
TRAINING_BATCH_SIZE=2

# Ac√∫mulo de Gradientes.
TRAINING_GRAD_ACCUMULATION=4

# Passos de aquecimento (Warmup).
TRAINING_WARMUP_STEPS=5

# Taxa de Aprendizado (Learning Rate).
TRAINING_LEARNING_RATE=2e-4

# Semente aleat√≥ria para reprodutibilidade.
TRAINING_SEED=3407

# N√∫mero de processos (CPUs) para processar o dataset.
TRAINING_DATASET_NUM_PROC=2

# Pasta onde checkpoints intermedi√°rios ser√£o salvos.
TRAINING_OUTPUT_DIR="outputs_checkpoints"

# Caminho do Dataset FINAL processado para ser usado no treino
DATASET_PATH="data/processed/train_dataset_final.jsonl"

# Onde salvar o modelo final convertido (GGUF)
FINAL_MODEL_NAME="models/planus_qwen_v1"

# ==========================================
# ‚öôÔ∏è PAR√ÇMETROS AVAN√áADOS DE TREINO
# ==========================================

# Otimizador. "adamw_8bit"
TRAINING_OPTIM="adamw_8bit"

# Weight Decay (Regulariza√ß√£o L2).
TRAINING_WEIGHT_DECAY=0.01

# Tipo de Scheduler da LR. "linear" ou "cosine"
TRAINING_LR_SCHEDULER="linear"

# ==========================================
# üîß LORA & PEFT CONFIG (Ajuste Fino Eficiente)
# ==========================================

LORA_R=16
LORA_ALPHA=16
LORA_DROPOUT=0
LORA_TARGET_MODULES='["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]'
LORA_RANDOM_STATE=3407

# M√©todo de quantiza√ß√£o para exporta√ß√£o GGUF.
GGUF_QUANTIZATION="q4_k_m"

# ==========================================
# ‚öôÔ∏è SISTEMA E CACHE (Avan√ßado)
# ==========================================

# HF_HOME=/mnt/dados/huggingface_cache
CUDA_VISIBLE_DEVICES=0
