# ==========================================
# üîê AUTENTICA√á√ÉO E ACESSOS
# ==========================================

# Hugging Face Token (OBRIGAT√ìRIO)
# Necess√°rio para baixar modelos "Gated" como Llama 3.1 ou fazer upload do seu modelo final.
# Crie um token com permiss√£o "Write" em: https://huggingface.co/settings/tokens
HF_TOKEN=hf_seu_token_aqui_xyz123

# ==========================================
# üìä MONITORAMENTO (Opcional, mas Recomendado)
# ==========================================

# Weights & Biases (WandB)
# Gera gr√°ficos lindos de Loss, VRAM e progresso em tempo real no navegador.
# Crie conta em: https://wandb.ai/
WANDB_API_KEY=
WANDB_PROJECT=planus-llm
WANDB_WATCH=false  # false √© mais leve, true loga gradientes (pesado)

# ==========================================
# ü§ñ CONFIGURA√á√ïES DO OLLAMA (Gerador de Dados)
# ==========================================

# Endere√ßo do Ollama (Padr√£o: http://localhost:11434)
# Se estiver rodando em docker ou outra m√°quina, altere aqui.
OLLAMA_HOST=http://localhost:11434

# Modelo usado para ler seus PDFs e criar as perguntas/respostas.
# IMPORTANTE: Voc√™ deve ter baixado o modelo antes (ex: ollama pull qwen2.5)
#
# Op√ß√µes Recomendadas:
# - llama3.1       (O Padr√£o. Equil√≠brio perfeito entre velocidade e obedi√™ncia a JSON)
# - qwen2.5        (Muitas vezes superior em l√≥gica e multil√≠ngue. Use 'qwen2.5:14b' se puder)
# - mistral-nemo   (Excelente janela de contexto e racioc√≠nio)
# - deepseek-r1    (√ìtimo racioc√≠nio, mas pode ser lento e verboso para gerar JSON simples)
GENERATOR_MODEL=llama3.1

SYNTHETIC_SOURCE_DIR="data/source_documents"
SYNTHETIC_OUTPUT_FILE="data/raw/train_data_synthetic.jsonl"
SYNTHETIC_GENERATOR_MODEL="llama3.1"
SYNTHETIC_SYSTEM_INSTRUCTION="Voc√™ √© o Planus, assistente virtual especializado do ERP Planuze. Responda perguntas baseando-se estritamente no contexto fornecido. Regras: 1) Ignore perguntas que n√£o tenham rela√ß√£o com o contexto. 2) NUNCA forne√ßa UUIDs ou chaves de banco de dados."

# ==========================================
# üèãÔ∏è CONFIGURA√á√ïES DE TREINAMENTO
# ==========================================
MODEL_NAME="unsloth/Qwen2.5-32B-Instruct"
MAX_SEQ_LENGTH=2048
LOAD_IN_4BIT=true

TRAINING_MAX_STEPS=60
TRAINING_BATCH_SIZE=2
TRAINING_OUTPUT_DIR="outputs_checkpoints"

DATASET_PATH="data/processed/train_dataset_final.jsonl"
FINAL_MODEL_NAME="models/planus_qwen_v1"

# ==========================================
# ‚öôÔ∏è SISTEMA E CACHE (Avan√ßado)
# ==========================================

# Caminho customizado para salvar os modelos baixados (Hugging Face Cache).
# √ötil se seu disco principal (C: ou /) for pequeno e voc√™ tiver um HD secund√°rio.
# Se deixar comentado, usa o padr√£o do sistema (~/.cache/huggingface).
# HF_HOME=/mnt/dados/huggingface_cache

# Define qual GPU usar (Se tiver m√∫ltiplas, ex: 0,1). Deixe vazio para usar todas.
CUDA_VISIBLE_DEVICES=0