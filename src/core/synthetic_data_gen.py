"""
M√≥dulo para gera√ß√£o de dados sint√©ticos usando Ollama.
"""
import os
import json
import re
import ollama
from pypdf import PdfReader
from tqdm import tqdm
from dotenv import load_dotenv
from src.core.utils.logger import logger
from config.settings import SyntheticConfig

# ==========================================
# CONFIGURA√á√ïES
# ==========================================

# Carrega vari√°veis de ambiente
load_dotenv()

# Carrega configura√ß√µes via dataclass centralizada
CONFIG = SyntheticConfig.from_env()

if not CONFIG.system_instruction:
    logger.warning(
        "‚ö†Ô∏è AVISO: Vari√°vel SYNTHETIC_SYSTEM_INSTRUCTION n√£o definida!")
    logger.warning("   Usando fallback vazio (Isso pode prejudicar o treino).")


# ==========================================
# FUN√á√ïES
# ==========================================


def _read_file_content(filepath):
    """
    L√™ o conte√∫do de um arquivo PDF ou TXT.
    """
    content = ""
    if filepath.endswith(".pdf"):
        reader = PdfReader(filepath)
        for page in reader.pages:
            extracted = page.extract_text()
            if extracted:
                content += extracted + "\n"
    elif filepath.endswith(".txt"):
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
    return content


def _create_chunks(content, filename):
    """
    Divide o conte√∫do em chunks para processamento.
    """
    chunks = []
    # Chunk size e overlap configur√°veis
    chunk_size = CONFIG.chunk_size
    # Sobreposi√ß√£o para n√£o perder contexto
    overlap = CONFIG.overlap

    for i in range(0, len(content), chunk_size - overlap):
        chunk = content[i:i+chunk_size]
        if len(chunk) > 100:  # Ignora peda√ßos muito pequenos
            chunks.append({
                "source": filename,
                "text": chunk
            })
    return chunks


def extract_text_from_files(directory):
    """
    L√™ todos os arquivos .pdf e .txt da pasta especificada.
    Retorna uma lista de dicion√°rios com 'source' (nome do arquivo) e 'text'
    (conte√∫do).
    """
    documents = []

    # Verifica se a pasta existe
    if not os.path.exists(directory):
        logger.error("‚ùå Erro: A pasta '%s' n√£o existe.", directory)
        return []

    files = [f for f in os.listdir(directory) if f.endswith(('.pdf', '.txt'))]
    logger.info("üìÇ Encontrados %d arquivos em: %s", len(files), directory)

    for filename in files:
        filepath = os.path.join(directory, filename)

        try:
            content = _read_file_content(filepath)

            # Se extraiu texto, quebra em peda√ßos (chunks) para n√£o estourar o
            # limite do Ollama
            if content:
                documents.extend(_create_chunks(content, filename))

        except Exception as e:  # pylint: disable=broad-exception-caught
            logger.error("‚ö†Ô∏è Erro ao ler %s: %s", filename, e)
            continue

    logger.info("‚úÖ Texto extra√≠do e fragmentado em %d partes.", len(documents))
    return documents


def _cleanup_json_response(content):
    """
    Tenta extrair e limpar o JSON da resposta do LLM.
    """
    # 1. Tenta encontrar bloco JSON com regex
    json_match = re.search(r'\[.*\]', content, re.DOTALL)
    if json_match:
        return json_match.group(0)

    # 2. Se n√£o achar lista, tenta objeto √∫nico
    json_match = re.search(r'\{.*\}', content, re.DOTALL)
    if json_match:
        # Se for um √∫nico objeto, envelopa em lista
        return f"[{json_match.group(0)}]"

    # 3. Fallback: limpeza b√°sica
    content = content.replace("```json", "").replace("```", "").strip()
    return content


def _process_single_document(doc):
    """
    Processa um √∫nico documento e gera pares de QA.
    """
    generated_rows = []

    # N√∫mero vari√°vel de exemplos por documento (5-8)
    num_examples = CONFIG.examples_per_chunk

    # O Prompt que pede para o LLM criar os dados
    prompt = (
        f"Analise o seguinte texto t√©cnico extra√≠do do arquivo "
        f"'{doc['source']}':\n\n"
        f"TEXTO:\n"
        f"\"{doc['text']}\"\n\n"
        f"TAREFA CR√çTICA:\n"
        f"Voc√™ √© um especialista em criar datasets de alta qualidade "
        f"para fine-tuning de LLMs.\n\n"
        f"Crie {num_examples} pares de intera√ß√£o Usu√°rio/Assistente "
        f"baseados EXCLUSIVAMENTE neste texto.\n\n"
        f"REQUISITOS OBRIGAT√ìRIOS:\n"
        f"1. VARIEDADE: Crie perguntas de diferentes tipos:\n"
        f"   - Perguntas simples e diretas (30%)\n"
        f"   - Perguntas compostas que requerem m√∫ltiplos dados (30%)\n"
        f"   - Perguntas que exigem racioc√≠nio ou compara√ß√£o (20%)\n"
        f"   - Perguntas contextualizadas (continua√ß√£o de conversa) (20%)\n\n"
        f"2. REALISMO: As perguntas devem simular usu√°rios reais do ERP:\n"
        f"   - Use linguagem natural e coloquial\n"
        f"   - Inclua ambiguidades ocasionais\n"
        f"   - Varie o n√≠vel de detalhe solicitado\n\n"
        f"3. SAUDA√á√ïES: EVITE come√ßar TODAS as respostas com "
        f"'Ol√° [nome]'.\n"
        f"   - 40% das respostas: SEM sauda√ß√£o (direto ao ponto)\n"
        f"   - 30% das respostas: Sauda√ß√£o variada (Bom dia, Claro, etc)\n"
        f"   - 30% das respostas: Com 'Ol√° [nome]'\n\n"
        f"4. COMPLEXIDADE: Varie a complexidade das respostas:\n"
        f"   - Respostas curtas e objetivas\n"
        f"   - Respostas com m√∫ltiplos dados estruturados\n"
        f"   - Respostas que explicam o racioc√≠nio\n\n"
        f"5. CONTEXTO: Inclua detalhes relevantes do texto original\n\n"
        f"FORMATO DE SA√çDA:\n"
        f"Retorne APENAS um JSON v√°lido (lista de objetos) sem markdown:\n\n"
        f"[\n"
        f"    {{\n"
        f"        \"contexto\": \"Resumo denso e rico da informa√ß√£o "
        f"relevante\",\n"
        f"        \"pergunta\": \"Pergunta natural e variada do usu√°rio\",\n"
        f"        \"resposta\": \"Resposta precisa SEM sauda√ß√£o repetitiva\"\n"
        f"    }}\n"
        f"]\n\n"
        f"IMPORTANTE: Gere exatamente {num_examples} exemplos diversos e "
        f"de alta qualidade."
    )

    try:

        # Chamada ao Ollama
        response = ollama.chat(model=CONFIG.generator_model, messages=[
            {
                'role': 'system',
                'content': ('Voc√™ √© um gerador de datasets JSON estrito. '
                            'Responda apenas com JSON v√°lido.')
            },
            {'role': 'user', 'content': prompt},
        ])

        content = response['message']['content']
        cleaned_content = _cleanup_json_response(content)

        # Tenta converter string para JSON
        data = json.loads(cleaned_content)

        # Se n√£o for lista, garante que seja
        if not isinstance(data, list):
            if isinstance(data, dict):
                data = [data]
            else:
                raise ValueError("JSON n√£o √© nem lista nem objeto")

        # Formata para o padr√£o final do treino (Unsloth/Alpaca format)
        for item in data:
            # Valida√ß√£o b√°sica de chaves
            required_keys = ("contexto", "pergunta", "resposta")
            if not all(k in item for k in required_keys):
                logger.warning("Skipping item missing keys")
                continue

            row = {
                "instruction": CONFIG.system_instruction,
                # O Input simula o que o sistema RAG entregaria para o
                # modelo em produ√ß√£o
                "input": (
                    f"[{CONFIG.chat_history}]: \n"
                    f"[{CONFIG.chat_subject}]: Documenta√ß√£o {doc['source']}\n"
                    f"[{CONFIG.chat_context}]: {item['contexto']}\n"
                    f"[{CONFIG.chat_question}]: {item['pergunta']}\n"
                    f"[{CONFIG.chat_language}]: pt"
                ),
                "output": item['resposta']
            }
            generated_rows.append(row)

    except json.JSONDecodeError:
        logger.warning("Failed to parse JSON for doc %s", doc['source'])
    except Exception as e:  # pylint: disable=broad-exception-caught
        logger.error("\n‚ùå Erro na API Ollama: %s", e)

    return generated_rows


def generate_synthetic_data(documents):
    """
    Usa o Ollama para ler cada trecho de texto e criar pares
    de Pergunta/Resposta.
    """
    logger.info(
        "ü§ñ Iniciando gera√ß√£o com o modelo '%s'... (Pode demorar)",
        CONFIG.generator_model
    )

    all_generated_rows = []

    # Barra de progresso para acompanhar
    for doc in tqdm(documents, desc="Processando documentos"):
        rows = _process_single_document(doc)
        all_generated_rows.extend(rows)

    return all_generated_rows


def save_jsonl(data, filename):
    """Salva a lista de objetos em um arquivo .jsonl"""
    # Garante que a pasta de destino existe (data/raw)
    os.makedirs(os.path.dirname(filename), exist_ok=True)

    logger.info("üíæ Salvando %d exemplos em %s...", len(data), filename)

    try:
        with open(filename, 'w', encoding='utf-8') as f:
            for entry in data:
                json.dump(entry, f, ensure_ascii=False)
                f.write('\n')
        logger.info("üöÄ Sucesso! Arquivo gerado.")

    except Exception as e:  # pylint: disable=broad-exception-caught
        logger.error("‚ùå Erro ao salvar arquivo: %s", e)


# ==========================================
# EXECU√á√ÉO PRINCIPAL
# ==========================================
if __name__ == "__main__":
    logger.info("--- INICIANDO GERADOR SINT√âTICO ---")

    # 1. Extrair Texto
    docs = extract_text_from_files(CONFIG.source_dir)

    if docs:
        # 2. Gerar Dados com IA
        dataset = generate_synthetic_data(docs)

        if dataset:
            # 3. Salvar Resultado
            save_jsonl(dataset, CONFIG.output_file)
        else:
            logger.warning(
                "‚ö†Ô∏è O modelo n√£o gerou dados v√°lidos. "
                "Verifique se Ollama est√° rodando."
            )
    else:
        logger.warning("‚ö†Ô∏è Nenhum documento encontrado.")
        logger.info("üëâ Coloque arquivos .pdf ou .txt na pasta: %s",
                    CONFIG.source_dir)
